{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Introduction\n",
    "\n",
    "Description\n",
    "\n",
    "In this time-series 'getting-started' competition, we are asked to forecast store sales on data from Corporaci√≥n Favorita, a large Ecuadorian-based grocery retailer. We need a model that can predict unit sales for thousands of items sold at different stores. For this competition we have different datasets describing sales, stores, holiday data and more between 2013 and 2017 in Ecuador.\n",
    "\n",
    "Goal\n",
    "\n",
    "To predict the sales per product, per store for the next 16 days.\n",
    "\n",
    "Metric\n",
    "\n",
    "The evaluation metric used for this competition is Root-Mean-Squared-Logarithmic-Error (RMSLE). (Taking logs means that errors in predicting big salesnumbers and smaller salesnumbers will affect the result more evenly.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "from re import search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(333)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Exploratory Data Analysis:\n",
    "1.1 Dataframes & NAs\n",
    "\n",
    "As a first step of the EDA we would like to know what our data looks like, and if there are any NAs in the dataset.\n",
    "\n",
    "We have different data sets to our disposal:\n",
    "\n",
    "    holiday_events: a list with all ecuadorian holidays and events;\n",
    "    oil: a list of oilprices meant to serve as an economic indicator of Ecuador;\n",
    "    stores: a dataset with information about our stores: includes city, state, type and others;\n",
    "    transactions: a dataset containing the number of aggregated transactions for each store on each day;\n",
    "    test: general testset of 16 days of sales we will need to predict;\n",
    "    train: a huge trainset with about 4 years of data to predict our test sales data.\n",
    "\n",
    "This notebook makes use of all datasets except for the oilprices as on the surface it didn't seem to give any improvement in the modelling results. This could potentially be added in a future update of this notebook if it does happen to be useful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 600001 entries, 0 to 600000\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   id           600001 non-null  int64  \n",
      " 1   date         600001 non-null  object \n",
      " 2   store_nbr    600001 non-null  int64  \n",
      " 3   family       600001 non-null  object \n",
      " 4   sales        600001 non-null  float64\n",
      " 5   onpromotion  600001 non-null  int64  \n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 27.5+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id             False\n",
       "date           False\n",
       "store_nbr      False\n",
       "family         False\n",
       "sales          False\n",
       "onpromotion    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read train/test data and check colnames & NA's:\n",
    "\n",
    "original_train = pd.read_csv('/workspaces/PracticeMachineLearning/data/store_sales_train_small.csv')\n",
    "original_test = pd.read_csv('/workspaces/PracticeMachineLearning/data/store_sales_test.csv')\n",
    "\n",
    "# Dataframe info:\n",
    "print(original_train.info())\n",
    "\n",
    "# Check NAs:\n",
    "original_train.isna().any()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have ID, date, store number, (product) family, saleprice and promotion columns. Our train and test datasets have zero missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2017-08-31'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find out how many stores, products and dates are in our data:\n",
    "\n",
    "original_train['store_nbr'].unique().__len__() # 54 stores\n",
    "original_train['family'].unique().__len__() # 33 products\n",
    "\n",
    "len(original_train) / 54 / 33 # 1684 days (between 4 and 5 years)\n",
    "original_train['date'].iloc[0] # 2013-01-01 is start\n",
    "original_train['date'].iloc[-1] # 2017-08-15 is end\n",
    "\n",
    "len(original_test) / 54 / 33 # 16 days\n",
    "original_test['date'].iloc[0] # 2017-08-16 is test start\n",
    "original_test['date'].iloc[-1] # 2017-08-31 is test end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
